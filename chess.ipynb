{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pygame\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from abc import ABC, abstractmethod\n",
    "from gym import spaces\n",
    "from typing import Union\n",
    "from collections import deque\n",
    "from pygame.font import Font\n",
    "from pygame.surface import Surface\n",
    "from torch.distributions.categorical import Categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let's make sure you have internet enabled\n",
    "import requests\n",
    "requests.get('http://www.google.com',timeout=10).ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you don't have internet access (it doesn't say \"True\" above)\n",
    "1. make sure your account is Phone Verified in [account settings](https://www.kaggle.com/settings)\n",
    "2. make sure internet is turned on in Settings -> Turn on internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# ensure we are on the latest version of kaggle-environments\n",
    "!pip install --upgrade kaggle-environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's set up the chess environment!\n",
    "from kaggle_environments import make\n",
    "env = make(\"chess\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should run a game in the environment between two random bots\n",
    "# NOTE: each game starts from a randomly selected opening\n",
    "result = env.run([\"random\", \"random\"])\n",
    "env.render(mode=\"ipython\", width=1000, height=1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your first agent\n",
    "Now let's create your first agent! The environment has the [Chessnut](https://github.com/cgearhart/Chessnut) pip package installed and we'll use that to parse the board state and generate moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chessnut.moves import MOVES\n",
    "print (MOVES['K']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learning(nn.Module, ABC):\n",
    "    def __init__(\n",
    "        self,\n",
    "        environment: gym.Env,\n",
    "        epochs: int,\n",
    "        gamma: float,\n",
    "        learning_rate: float\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.state_dim = environment.observation_space.shape[0]\n",
    "        self.action_dim = environment.action_space.n\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.device = T.device(\"cuda:0\" if T.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def take_action(self, state: np.ndarray, *args):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def learn(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def remember(self, *args):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save(self, folder: str):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Cell = tuple[int]\n",
    "Action = tuple[Cell, Cell]\n",
    "Trajectory = tuple[np.ndarray, float, bool, dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = 0\n",
    "PAWN = 1\n",
    "BISHOP = 2\n",
    "KNIGHT = 3\n",
    "ROOK = 4\n",
    "QUEEN = 5\n",
    "KING = 6\n",
    "\n",
    "BLACK = 0\n",
    "WHITE = 1\n",
    "\n",
    "ASCIIS = (\n",
    "    (\"♙\", \"♗\", \"♘\", \"♖\", \"♕\", \"♔\"),\n",
    "    (\"♟︎\", \"♝\", \"♞\", \"♜\", \"♛\", \"♚\"),\n",
    ")\n",
    "\n",
    "def get_ascii(color: int, piece: int):\n",
    "    return ASCIIS[color][piece - 1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVE = -1\n",
    "\n",
    "CHECK_WIN = 10\n",
    "CHECK_LOSE = -CHECK_WIN\n",
    "\n",
    "CHECK_MATE_WIN = 100\n",
    "CHECK_MATE_LOSE = -CHECK_MATE_WIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Info keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRONG_MOVE = \"wrong_move\"\n",
    "EMPTY_SELECT = \"empty_select\"\n",
    "CHECK_WIN = \"check_win\"\n",
    "CHECK_LOSE = \"check_lose\"\n",
    "CHECK_MATE_WIN = \"check_mate_win\"\n",
    "CHECK_MATE_LOSE = \"check_mate_lose\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK_color = (000,) * 3\n",
    "GRAY_color  = (128,) * 3\n",
    "WHITE_color = (255,) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_MOVES = {\n",
    "    \"king\": 8,\n",
    "    \"knight\": 8,\n",
    "    \"rook\": 7 * 4,\n",
    "    \"bishop\": 7 * 4,\n",
    "    \"queen\": 7 * 4 * 2,\n",
    "    \"pawn\": 7 * 4 * 2,\n",
    "}\n",
    "\n",
    "KING_moves = ((-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1))\n",
    "\n",
    "ROOK_moves = (\n",
    "    (1, 0),\n",
    "    (2, 0),\n",
    "    (3, 0),\n",
    "    (4, 0),\n",
    "    (5, 0),\n",
    "    (6, 0),\n",
    "    (7, 0),\n",
    "    (-1, 0),\n",
    "    (-2, 0),\n",
    "    (-3, 0),\n",
    "    (-4, 0),\n",
    "    (-5, 0),\n",
    "    (-6, 0),\n",
    "    (-7, 0),\n",
    "    (0, 1),\n",
    "    (0, 2),\n",
    "    (0, 3),\n",
    "    (0, 4),\n",
    "    (0, 5),\n",
    "    (0, 6),\n",
    "    (0, 7),\n",
    "    (0, -1),\n",
    "    (0, -2),\n",
    "    (0, -3),\n",
    "    (0, -4),\n",
    "    (0, -5),\n",
    "    (0, -6),\n",
    "    (0, -7),\n",
    ")\n",
    "BISHOP_moves = (\n",
    "    (1, 1),\n",
    "    (1, -1),\n",
    "    (2, 2),\n",
    "    (3, 3),\n",
    "    (4, 4),\n",
    "    (5, 5),\n",
    "    (6, 6),\n",
    "    (7, 7),\n",
    "    (2, -2),\n",
    "    (3, -3),\n",
    "    (4, -4),\n",
    "    (5, -5),\n",
    "    (6, -6),\n",
    "    (7, -7),\n",
    "    (-1, 1),\n",
    "    (-2, 2),\n",
    "    (-3, 3),\n",
    "    (-4, 4),\n",
    "    (-5, 5),\n",
    "    (-6, 6),\n",
    "    (-7, 7),\n",
    "    (-1, -1),\n",
    "    (-2, -2),\n",
    "    (-3, -3),\n",
    "    (-4, -4),\n",
    "    (-5, -5),\n",
    "    (-6, -6),\n",
    "    (-7, -7),\n",
    ")\n",
    "\n",
    "KNIGHT_moves = (\n",
    "    (2, 1),\n",
    "    (2, -1),\n",
    "    (-2, 1),\n",
    "    (-2, -1),\n",
    "    (1, 2),\n",
    "    (1, -2),\n",
    "    (-1, 2),\n",
    "    (-1, -2),\n",
    ")\n",
    "\n",
    "QUEEN_moves = BISHOP_moves + ROOK_moves\n",
    "\n",
    "PAWN_moves = ((1, 0), (2, 0), (1, 1), (1, -1)) + ROOK_moves[2:] + BISHOP_moves[1:]\n",
    "\n",
    "PIECE_MOVE = [\n",
    "    None,\n",
    "    PAWN_moves,\n",
    "    BISHOP_moves,\n",
    "    KNIGHT_moves,\n",
    "    ROOK_moves,\n",
    "    QUEEN_moves,\n",
    "    KING_moves\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(QUEEN)\n",
    "board = np.zeros((2, 8, 8), dtype=np.uint8)\n",
    "board[:, 0, 3] = QUEEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_model(\n",
    "    input_size: int,\n",
    "    hidden_layers: tuple[int],\n",
    "    output_size: int,\n",
    "    last_activation: nn.Module = nn.Identity(),\n",
    ") -> nn.Module:\n",
    "    layers = [\n",
    "        nn.Linear(input_size, hidden_layers[0]),\n",
    "        nn.ReLU(),\n",
    "    ]\n",
    "\n",
    "    for i in range(len(hidden_layers) - 1):\n",
    "        in_features = hidden_layers[i]\n",
    "        out_features = hidden_layers[i + 1]\n",
    "        layers += [\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "\n",
    "    layers += [nn.Linear(hidden_layers[-1], output_size), last_activation]\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def make_batch_ids(n: int, batch_size: int, shuffle: bool = True) -> np.ndarray:\n",
    "    starts = np.arange(0, n, batch_size)\n",
    "    indices = np.arange(n, dtype=np.int64)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    return [indices[i : i + batch_size] for i in starts]\n",
    "\n",
    "\n",
    "def tensor_to_numpy(x: T.Tensor) -> np.ndarray:\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def save_to_video(path: str, frames: np.ndarray, fps: int = 2):\n",
    "    size = frames.shape[1:3]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(\n",
    "        path,\n",
    "        fourcc,\n",
    "        fps,\n",
    "        size,\n",
    "    )\n",
    "    for f in frames:\n",
    "        out.write(f)\n",
    "    out.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVE_reward = -1\n",
    "\n",
    "CHECK_WIN_reward = 10\n",
    "CHECK_LOSE_reward = -CHECK_WIN_reward\n",
    "\n",
    "CHECK_MATE_WIN_reward = 100\n",
    "CHECK_MATE_LOSE_reward = -CHECK_MATE_WIN_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fen to board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dic = {\n",
    "    'p' : 1,\n",
    "    \"b\" : 2,\n",
    "    \"n\" : 3,\n",
    "    \"r\" : 4,\n",
    "    \"q\" : 5,\n",
    "    \"k\" : 6\n",
    "    }\n",
    "def fen_board(fen:str):\n",
    "    fen = fen.split(' ')\n",
    "    fen_board = fen[0]\n",
    "    turn = fen[1] \n",
    "    fen_lines = fen_board.split(\"/\")\n",
    "    # Handle White \n",
    "    white_pos = T.zeros(size=(8,8))\n",
    "    i=0\n",
    "    \n",
    "    while i<8:\n",
    "        j=0\n",
    "        empties=0\n",
    "        while j<len(fen_lines[i]):\n",
    "            print(i,j)\n",
    "            if fen_lines[i][j].isupper():\n",
    "                print(piece_dic.get(fen_lines[i][j].lower()))\n",
    "                white_pos[i][j+empties]=piece_dic.get(fen_lines[i][j].lower())\n",
    "            elif fen_lines[i][j].isdigit():\n",
    "                empties+=int(fen_lines[i][j])-1\n",
    "            j+=1\n",
    "        i+=1\n",
    "    # Handle Black\n",
    "    black_pos = T.zeros(size=(8,8))\n",
    "    i=0\n",
    "    while i<8:\n",
    "        j = 0\n",
    "        empties = 0 \n",
    "        while j<len(fen_lines[i]):\n",
    "            if fen_lines[i][j].islower():\n",
    "                black_pos[i][empties+j]=piece_dic.get(fen_lines[i][j])\n",
    "            elif fen_lines[i][j].isdigit():\n",
    "                empties+=int(fen_lines[i][j])-1\n",
    "            j+=1\n",
    "        i+=1\n",
    "    if turn=='w':\n",
    "        board = T.concat(tensors=(white_pos.flip(dims=[0]).unsqueeze(dim=0),black_pos.unsqueeze(dim=0)),dim=0)\n",
    "    else : \n",
    "        board = T.concat(tensors=(black_pos.unsqueeze(dim=0),white_pos.unsqueeze(dim=0)),dim=0)\n",
    "    return board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chess(gym.Env):\n",
    "    metadata: dict = {\n",
    "        \"render_mode\": (\"human\", \"rgb_array\"),\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_steps: int = 6000,\n",
    "        render_mode: str = \"human\",\n",
    "        window_size: int = 800,\n",
    "    ) -> None:\n",
    "        self.action_space = spaces.Discrete(640)\n",
    "        self.observation_space = spaces.Box(0, 7, (128,), dtype=np.int32)\n",
    "\n",
    "        self.board: np.ndarray = self.init_board()\n",
    "        self.pieces: list[dict] = self.init_pieces()\n",
    "        self.pieces_names: list[str] = self.get_pieces_names()\n",
    "\n",
    "        self.turn: int = WHITE\n",
    "        self.done: bool = False\n",
    "        self.steps: int = 0\n",
    "        self.checked: bool = [False, False]\n",
    "        self.max_steps: int = max_steps\n",
    "\n",
    "        self.font: Font = None\n",
    "        self.cell_size: int = window_size // 8\n",
    "        self.screen: Surface = None\n",
    "        self.window_size: int = window_size\n",
    "        self.render_mode: str = render_mode\n",
    "\n",
    "    def init_board(self) -> np.ndarray:\n",
    "        board = np.zeros((2, 8, 8), dtype=np.uint8)\n",
    "        board[:, 0, 3] = QUEEN\n",
    "        board[:, 0, 4] = KING\n",
    "        board[:, 1, :] = PAWN\n",
    "        board[:, 0, (0, 7)] = ROOK\n",
    "        board[:, 0, (1, 6)] = KNIGHT\n",
    "        board[:, 0, (2, 5)] = BISHOP\n",
    "        return board\n",
    "\n",
    "    def init_pieces(self):\n",
    "        pieces = {\n",
    "            \"pawn_1\": (1, 0),\n",
    "            \"pawn_2\": (1, 1),\n",
    "            \"pawn_3\": (1, 2),\n",
    "            \"pawn_4\": (1, 3),\n",
    "            \"pawn_5\": (1, 4),\n",
    "            \"pawn_6\": (1, 5),\n",
    "            \"pawn_7\": (1, 6),\n",
    "            \"pawn_8\": (1, 7),\n",
    "            \"rook_1\": (0, 0),\n",
    "            \"rook_2\": (0, 7),\n",
    "            \"knight_1\": (0, 1),\n",
    "            \"knight_2\": (0, 6),\n",
    "            \"bishop_1\": (0, 2),\n",
    "            \"bishop_2\": (0, 5),\n",
    "            \"queen\": (0, 3),\n",
    "            \"king\": (0, 4),\n",
    "        }\n",
    "\n",
    "        return [pieces.copy(), pieces.copy()]\n",
    "\n",
    "    def get_state(self, turn: int) -> np.ndarray:\n",
    "        arr = self.board.copy()\n",
    "        print(arr[0],arr[1])\n",
    "        if turn == WHITE:\n",
    "            arr[[0, 1]] = arr[[1, 0]]\n",
    "        return arr.flatten()\n",
    "\n",
    "    def draw_cells(self):\n",
    "        for y in range(8):\n",
    "            for x in range(8):\n",
    "                self.draw_cell(x, y)\n",
    "\n",
    "    def draw_pieces(self):\n",
    "        for y in range(8):\n",
    "            for x in range(8):\n",
    "                self.draw_piece(x, y)\n",
    "\n",
    "    def render(self) -> Union[None, np.ndarray]:\n",
    "        self.init_pygame()\n",
    "        self.screen.fill(BLACK_color)\n",
    "        self.draw_cells()\n",
    "        self.draw_pieces()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.display.flip()\n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
    "            )\n",
    "\n",
    "    def init_pygame(self) -> None:\n",
    "        if self.screen is not None:\n",
    "            return\n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "        self.font = pygame.font.Font(\"./seguisym.ttf\", self.cell_size // 2)\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.display.init()\n",
    "            self.screen = pygame.display.set_mode((self.window_size,) * 2)\n",
    "            pygame.display.set_caption(\"Chess RL Environment\")\n",
    "        else:\n",
    "            self.screen = pygame.Surface((self.window_size,) * 2)\n",
    "\n",
    "    def get_cell_color(self, x: int, y: int) -> tuple[int]:\n",
    "        if (x + y) % 2 == 0:\n",
    "            return GRAY_color\n",
    "        return BLACK_color\n",
    "\n",
    "    def get_left_top(self, x: int, y: int, offset: float = 0) -> tuple[int]:\n",
    "        return self.cell_size * x + offset, self.cell_size * y + offset\n",
    "\n",
    "    def draw_cell(self, x: int, y: int) -> None:\n",
    "        pygame.draw.rect(\n",
    "            self.screen,\n",
    "            self.get_cell_color(x, y),\n",
    "            pygame.Rect((*self.get_left_top(x, y), self.cell_size, self.cell_size)),\n",
    "        )\n",
    "\n",
    "    def draw_piece(self, x: int, y: int) -> None:\n",
    "        row, col = y, x\n",
    "        for color in [BLACK, WHITE]:\n",
    "\n",
    "            if self.is_empty((row, col), color):\n",
    "                continue\n",
    "\n",
    "            yy = abs((color * 7) - y)\n",
    "            text = self.font.render(\n",
    "                get_ascii(color, self.board[color, row, col]),\n",
    "                True,\n",
    "                WHITE_color,\n",
    "                self.get_cell_color(x, yy),\n",
    "            )\n",
    "            rect = text.get_rect()\n",
    "            rect.center = self.get_left_top(x, yy, offset=self.cell_size // 2)\n",
    "            self.screen.blit(text, rect)\n",
    "\n",
    "    def close(self) -> None:\n",
    "        if self.screen is None:\n",
    "            return\n",
    "        pygame.display.quit()\n",
    "        pygame.quit()\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        self.done = False\n",
    "        self.turn = WHITE\n",
    "        self.steps = 0\n",
    "        self.board = self.init_board()\n",
    "        self.pieces = self.init_pieces()\n",
    "        self.checked = [False, False]\n",
    "\n",
    "    def get_pieces_names(self) -> set:\n",
    "        return list(self.pieces[0].keys())\n",
    "\n",
    "    def is_in_range(self, pos: Cell) -> bool:\n",
    "        row, col = pos\n",
    "        return row >= 0 and row <= 7 and col >= 0 and col <= 7\n",
    "\n",
    "    def get_size(self, name: str):\n",
    "        return POSSIBLE_MOVES[name]\n",
    "\n",
    "    def get_empty_actions(self, name: str):\n",
    "        size = self.get_size(name)\n",
    "        possibles = np.zeros((size, 2), dtype=np.int32)\n",
    "        actions_mask = np.zeros((size), dtype=np.int32)\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    def is_path_empty(self, current_pos: Cell, next_pos: Cell, turn: int) -> bool:\n",
    "        next_row, next_col = next_pos\n",
    "        current_row, current_col = current_pos\n",
    "\n",
    "        diff_row = next_row - current_row\n",
    "        diff_col = next_col - current_col\n",
    "        sign_row = np.sign(next_row - current_row)\n",
    "        sign_col = np.sign(next_col - current_col)\n",
    "\n",
    "        size = max(abs(diff_row), abs(diff_col)) - 1\n",
    "        rows = np.zeros(size, dtype=np.int32) + next_row\n",
    "        cols = np.zeros(size, dtype=np.int32) + next_col\n",
    "\n",
    "        if diff_row:\n",
    "            rows = np.arange(current_row + sign_row, next_row, sign_row, dtype=np.int32)\n",
    "\n",
    "        if diff_col:\n",
    "            cols = np.arange(current_col + sign_col, next_col, sign_col, dtype=np.int32)\n",
    "\n",
    "        for pos in zip(rows, cols):\n",
    "            if not self.both_side_empty(tuple(pos), turn):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def piece_can_jump(self, pos: Cell, turn: int) -> bool:\n",
    "        jumps = {KNIGHT, KING}\n",
    "        piece = self.board[turn, pos[0], pos[1]]\n",
    "        return piece in jumps\n",
    "\n",
    "    def general_validation(\n",
    "        self,\n",
    "        current_pos: Cell,\n",
    "        next_pos: Cell,\n",
    "        turn: int,\n",
    "        deny_enemy_king: bool,\n",
    "    ) -> bool:\n",
    "        if not self.is_in_range(next_pos):\n",
    "            return False\n",
    "\n",
    "        if not self.is_empty(next_pos, turn):\n",
    "            return False\n",
    "\n",
    "        if self.is_enemy_king(next_pos, turn) and (not deny_enemy_king):\n",
    "            return False\n",
    "\n",
    "        if (not self.piece_can_jump(current_pos, turn)) and (\n",
    "            not self.is_path_empty(current_pos, next_pos, turn)\n",
    "        ):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def is_valid_move(\n",
    "        self,\n",
    "        current_pos: Cell,\n",
    "        next_pos: Cell,\n",
    "        turn: int,\n",
    "        deny_enemy_king: bool,\n",
    "    ) -> bool:\n",
    "        if not self.general_validation(current_pos, next_pos, turn, deny_enemy_king):\n",
    "            return False\n",
    "        if self.is_lead_to_check(current_pos, next_pos, turn):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def is_lead_to_check(self, current_pos: int, next_pos: int, turn: int) -> bool:\n",
    "        temp = Chess(render_mode=\"rgb_array\")\n",
    "        temp.board = np.copy(self.board)\n",
    "        temp.move_piece(current_pos, next_pos, turn)\n",
    "        return temp.is_check(temp.get_pos_king(turn), turn)\n",
    "\n",
    "    def get_actions_for_bishop(\n",
    "        self, pos: Cell, turn: int, deny_enemy_king: bool = False\n",
    "    ):\n",
    "        possibles, actions_mask = self.get_empty_actions(\"bishop\")\n",
    "        if pos is None:\n",
    "            return possibles, actions_mask\n",
    "\n",
    "        row, col = pos\n",
    "        for i, (r, c) in enumerate(BISHOP_moves):\n",
    "            next_pos = (row + r, col + c)\n",
    "\n",
    "            if not self.is_valid_move(pos, next_pos, turn, deny_enemy_king):\n",
    "                continue\n",
    "\n",
    "            possibles[i] = next_pos\n",
    "            actions_mask[i] = 1\n",
    "\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    def get_actions_for_rook(self, pos: Cell, turn: int, deny_enemy_king: bool = False):\n",
    "        possibles, actions_mask = self.get_empty_actions(\"rook\")\n",
    "        if pos is None:\n",
    "            return possibles, actions_mask\n",
    "\n",
    "        row, col = pos\n",
    "        for i, (r, c) in enumerate(ROOK_moves):\n",
    "            next_pos = (row + r, col + c)\n",
    "\n",
    "            if not self.is_valid_move(pos, next_pos, turn, deny_enemy_king):\n",
    "                continue\n",
    "\n",
    "            possibles[i] = next_pos\n",
    "            actions_mask[i] = 1\n",
    "\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    def get_action_for_queen(self, pos: Cell, turn: int, deny_enemy_king: bool = False):\n",
    "        possibles_rook, actions_mask_rook = self.get_actions_for_rook(\n",
    "            pos, turn, deny_enemy_king\n",
    "        )\n",
    "        possibles_bishop, actions_mask_bishop = self.get_actions_for_bishop(\n",
    "            pos, turn, deny_enemy_king\n",
    "        )\n",
    "        possibles = np.concatenate([possibles_bishop, possibles_rook])\n",
    "        actions_mask = np.concatenate([actions_mask_bishop, actions_mask_rook])\n",
    "\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    def get_actions_for_pawn(self, pos: Cell, turn: int, deny_enemy_king: bool = False):\n",
    "        possibles, actions_mask = self.get_empty_actions(\"pawn\")\n",
    "        if pos is None:\n",
    "            return possibles, actions_mask\n",
    "\n",
    "        row, col = pos\n",
    "        if self.board[turn, row, col] == QUEEN:\n",
    "            return self.get_action_for_queen(pos, turn)\n",
    "\n",
    "        for i, (r, c) in enumerate(PAWN_moves[:4]):\n",
    "            next_pos = (row + r, col + c)\n",
    "\n",
    "            if not self.is_valid_move(pos, next_pos, turn, deny_enemy_king):\n",
    "                continue\n",
    "\n",
    "            can_moves = (\n",
    "                (r == 1 and c == 0 and self.both_side_empty(next_pos, turn)),\n",
    "                (r == 2 and row == 1 and self.both_side_empty(next_pos, turn)),\n",
    "                (r == 1 and abs(c) == 1 and self.check_for_enemy(next_pos, turn)),\n",
    "                # TODO: EN PASSANT\n",
    "            )\n",
    "\n",
    "            if True in can_moves:\n",
    "                possibles[i] = next_pos\n",
    "                actions_mask[i] = 1\n",
    "\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    def get_actions_for_knight(\n",
    "        self, pos: Cell, turn: int, deny_enemy_king: bool = False\n",
    "    ):\n",
    "        possibles, actions_mask = self.get_empty_actions(\"knight\")\n",
    "\n",
    "        if pos is None:\n",
    "            return possibles, actions_mask\n",
    "\n",
    "        row, col = pos\n",
    "        for i, (r, c) in enumerate(KNIGHT_moves):\n",
    "            next_pos = (row + r, col + c)\n",
    "            if not self.is_valid_move(pos, next_pos, turn, deny_enemy_king):\n",
    "                continue\n",
    "\n",
    "            possibles[i] = next_pos\n",
    "            actions_mask[i] = 1\n",
    "\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    def get_actions_for_king(self, pos: Cell, turn: int):\n",
    "        pos\n",
    "        row, col = pos\n",
    "        possibles, actions_mask = self.get_empty_actions(\"king\")\n",
    "\n",
    "        for i, (r, c) in enumerate(KING_moves):\n",
    "            next_pos = (row + r, col + c)\n",
    "\n",
    "            if not self.is_valid_move(pos, next_pos, turn, False):\n",
    "                continue\n",
    "\n",
    "            if self.is_neighbor_enemy_king(next_pos, turn):\n",
    "                continue\n",
    "\n",
    "            possibles[i] = next_pos\n",
    "            actions_mask[i] = 1\n",
    "\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    def get_source_pos(self, name: str, turn: int):\n",
    "        cat = name.split(\"_\")[0]\n",
    "        pos = self.pieces[turn][name]\n",
    "        if pos is None:\n",
    "            pos = (0, 0)\n",
    "        size = self.get_size(cat)\n",
    "        return np.array([pos] * size)\n",
    "\n",
    "    def get_actions_for(self, name: str, turn: int, deny_enemy_king: bool = False):\n",
    "        assert name in self.pieces_names, f\"name not in {self.pieces_names}\"\n",
    "        piece_cat = name.split(\"_\")[0]\n",
    "        piece_pos = self.pieces[turn][name]\n",
    "        src_poses = self.get_source_pos(name, turn)\n",
    "\n",
    "        if piece_cat == \"pawn\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *self.get_actions_for_pawn(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"knight\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *self.get_actions_for_knight(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"rook\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *self.get_actions_for_rook(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"bishop\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *self.get_actions_for_bishop(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"queen\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *self.get_action_for_queen(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"king\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *self.get_actions_for_king(piece_pos, turn),\n",
    "            )\n",
    "\n",
    "    def get_all_actions(self, turn: int, deny_enemy_king: bool = False):\n",
    "        all_possibles = []\n",
    "        all_source_pos = []\n",
    "        all_actions_mask = []\n",
    "        for name in self.pieces[turn].keys():\n",
    "            # DENY ENEMY KING == FOR CHECKMATE VALIDATION ONLY SO ....\n",
    "            if name == \"king\" and deny_enemy_king:\n",
    "                continue\n",
    "\n",
    "            source_pos, possibles, actions_mask = self.get_actions_for(\n",
    "                name, turn, deny_enemy_king\n",
    "            )\n",
    "            all_source_pos.append(source_pos)\n",
    "            all_possibles.append(possibles)\n",
    "            all_actions_mask.append(actions_mask)\n",
    "\n",
    "        return (\n",
    "            np.concatenate(all_source_pos),\n",
    "            np.concatenate(all_possibles),\n",
    "            np.concatenate(all_actions_mask),\n",
    "        )\n",
    "\n",
    "    def check_for_enemy(self, pos: Cell, turn: int) -> bool:\n",
    "        r, c = pos\n",
    "        return not self.is_empty((7 - r, c), 1 - turn)\n",
    "\n",
    "    def is_empty(self, pos: Cell, turn: int) -> bool:\n",
    "        return self.board[turn, pos[0], pos[1]] == EMPTY\n",
    "\n",
    "    def is_enemy_king(self, pos: Cell, turn: int) -> bool:\n",
    "        r, c = pos\n",
    "        return self.board[1 - turn, 7 - r, c] == KING\n",
    "\n",
    "    def both_side_empty(self, pos: Cell, turn: int) -> bool:\n",
    "        r, c = pos\n",
    "        return self.is_empty(pos, turn) and self.is_empty((7 - r, c), 1 - turn)\n",
    "\n",
    "    def get_pos_king(self, turn: int) -> Cell:\n",
    "        row, col = np.where(self.board[turn] == KING)\n",
    "        return row[0], col[0]\n",
    "\n",
    "    def is_neighbor_enemy_king(self, pos: Cell, turn: int) -> bool:\n",
    "        row, col = pos\n",
    "        row_enemy_king, col_enemy_king = self.get_pos_king(1 - turn)\n",
    "        row_enemy_king = 7 - row_enemy_king\n",
    "        diff_row = abs(row - row_enemy_king)\n",
    "        diff_col = abs(col - col_enemy_king)\n",
    "        return diff_row <= 1 and diff_col <= 1\n",
    "\n",
    "    def is_check(self, king_pos: Cell, turn: int) -> bool:\n",
    "        rk, ck = king_pos\n",
    "        \n",
    "        # GO TO UP ROW\n",
    "        for r in range(rk + 1, 8):\n",
    "            if not self.is_empty((r, ck), turn):\n",
    "                break\n",
    "            p = self.board[1 - turn, 7 - r, ck]\n",
    "            if p == ROOK or p == QUEEN:\n",
    "                return True\n",
    "        \n",
    "        # GO TO DOWN ROW\n",
    "        for r in range(rk - 1, -1, -1):\n",
    "            if not self.is_empty((r, ck), turn):\n",
    "                break\n",
    "            p = self.board[1 - turn, 7 - r, ck]\n",
    "            if p == ROOK or p == QUEEN:\n",
    "                return True\n",
    "        \n",
    "        # GO TO RIGHT COL\n",
    "        for c in range(ck + 1, 8):\n",
    "            if not self.is_empty((rk, c), turn):\n",
    "                break\n",
    "            p = self.board[1 - turn, 7 - rk, c]\n",
    "            if p == ROOK or p == QUEEN:\n",
    "                return True\n",
    "\n",
    "        # GOT TO LEFT COL\n",
    "        for c in range(ck - 1, -1, -1):\n",
    "            if not self.is_empty((rk, c), turn):\n",
    "                break\n",
    "            p = self.board[1 - turn, 7 - rk, c]\n",
    "            if p == ROOK or p == QUEEN:\n",
    "                return True\n",
    "\n",
    "        # CROSS DOWN\n",
    "        for r in range(rk + 1, 8):\n",
    "            # RIGHT\n",
    "            d = r - rk\n",
    "            for c in [ck + d, ck - d]:\n",
    "                if not self.is_in_range((r, c)):\n",
    "                    continue\n",
    "\n",
    "                if not self.is_empty((r, c), turn):\n",
    "                    break\n",
    "\n",
    "                p = self.board[1 - turn, 7 - r, c]\n",
    "                if p == BISHOP or p == QUEEN:\n",
    "                    return True\n",
    "                \n",
    "                if d == 1 and p == PAWN:\n",
    "                    return True\n",
    "\n",
    "        # CROSS UP\n",
    "        for r in range(rk - 1, -1, -1):\n",
    "            d = r - rk\n",
    "            for c in [ck + d, ck - d]:\n",
    "                if not self.is_in_range((r, c)):\n",
    "                    continue\n",
    "\n",
    "                if not self.is_empty((r, c), turn):\n",
    "                    break\n",
    "\n",
    "                p = self.board[1 - turn, 7 - r, c]\n",
    "                if p == BISHOP or p == QUEEN:\n",
    "                    return True\n",
    "\n",
    "\n",
    "        # KNIGHTS\n",
    "        for r, c in KNIGHT_moves:\n",
    "            nr, nc = rk + r, ck + c\n",
    "            if not self.is_in_range((nr, nc)):\n",
    "                continue\n",
    "            if self.board[1 - turn, 7 - nr, nc] == KNIGHT:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def update_checks(self, rewards: list[int] = None, infos: list[set] = None):\n",
    "        rewards = [0, 0] if rewards is None else rewards\n",
    "        infos = [set(), set()] if infos is None else infos\n",
    "\n",
    "        for turn in range(2):\n",
    "            king_pos = self.get_pos_king(turn)\n",
    "            is_check = self.is_check(king_pos, turn)\n",
    "            self.checked[turn] = is_check\n",
    "            if is_check:\n",
    "                rewards[turn] += CHECK_LOSE_reward\n",
    "                rewards[1 - turn] += CHECK_WIN_reward\n",
    "\n",
    "                infos[turn].add(CHECK_LOSE)\n",
    "                infos[1 - turn].add(CHECK_WIN)\n",
    "                break\n",
    "        return rewards, infos\n",
    "\n",
    "    def update_check_mates(self, rewards: list[int] = None, infos: list[set] = None):\n",
    "        rewards = [0, 0] if rewards is None else rewards\n",
    "        infos = [set(), set()] if infos is None else infos\n",
    "\n",
    "        for turn in range(2):\n",
    "            _, _, actions = self.get_all_actions(turn)\n",
    "            if np.sum(actions) == 0:\n",
    "                self.done = True\n",
    "                rewards[turn] += CHECK_MATE_LOSE_reward\n",
    "                rewards[1 - turn] +=CHECK_MATE_WIN_reward\n",
    "\n",
    "                infos[turn].add(CHECK_MATE_LOSE)\n",
    "                infos[1 - turn].add(CHECK_MATE_WIN)\n",
    "                break\n",
    "\n",
    "        return rewards, infos\n",
    "\n",
    "    def move_piece(self, current_pos: Cell, next_pos: Cell, turn: int):\n",
    "        next_row, next_col = next_pos\n",
    "        current_row, current_col = current_pos\n",
    "        self.board[turn, next_row, next_col] = self.board[\n",
    "            turn, current_row, current_col\n",
    "        ]\n",
    "\n",
    "        self.promote_pawn(next_pos, turn)\n",
    "        self.board[turn, current_row, current_col] = EMPTY\n",
    "        self.board[1 - turn, 7 - next_row, next_col] = EMPTY\n",
    "\n",
    "        for (key, value) in self.pieces[turn].items():\n",
    "            if value == tuple(current_pos):\n",
    "                self.pieces[turn][key] = tuple(next_pos)\n",
    "\n",
    "        for (key, value) in self.pieces[1 - turn].items():\n",
    "            if value == (7 - next_pos[0], next_pos[1]):\n",
    "                self.pieces[1 - turn][key] = None\n",
    "\n",
    "        rewards = [MOVE_reward, MOVE_reward]\n",
    "        rewards[1 - turn] *= 2\n",
    "\n",
    "        return rewards, [set(), set()]\n",
    "\n",
    "    def is_game_done(self):\n",
    "        return self.done or (self.steps >= self.max_steps)\n",
    "\n",
    "    def promote_pawn(self, pos: Cell, turn: int):\n",
    "        row, col = pos\n",
    "        if self.board[turn, row, col] == PAWN and row == 7:\n",
    "            self.board[turn, row, col] = QUEEN\n",
    "\n",
    "    def step(self, action: int):\n",
    "        assert not self.is_game_done(), \"the game is finished reset\"\n",
    "        assert action < 640, \"action number must be less than 640\"\n",
    "\n",
    "        source_pos, possibles, actions_mask = self.get_all_actions(self.turn)\n",
    "        assert actions_mask[action], f\"Cannot Take This Action = {action}\"\n",
    "        rewards, infos = self.move_piece(\n",
    "            source_pos[action], possibles[action], self.turn\n",
    "        )\n",
    "        rewards, infos = self.update_checks(rewards, infos)\n",
    "        rewards, infos = self.update_check_mates(rewards, infos)\n",
    "\n",
    "        self.turn = 1 - self.turn\n",
    "        self.steps += 1\n",
    "        return rewards, self.is_game_done(), infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer(ABC):\n",
    "    def __init__(self, max_size: int, batch_size: int, shuffle: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.shuffle = shuffle\n",
    "        self.max_size = max_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    @abstractmethod\n",
    "    def add(self, *args) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def clear(self) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_len(self) -> int:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.get_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Episode:\n",
    "    def __init__(self) -> None:\n",
    "        self.goals = []\n",
    "        self.probs = []\n",
    "        self.masks = []\n",
    "        self.values = []\n",
    "        self.states = []\n",
    "        self.rewards = []\n",
    "        self.actions = []\n",
    "\n",
    "    def add(\n",
    "        self,\n",
    "        state: np.ndarray,\n",
    "        reward: float,\n",
    "        action,\n",
    "        goal: bool,\n",
    "        prob: float = None,\n",
    "        value: float = None,\n",
    "        masks: np.ndarray = None,\n",
    "    ):\n",
    "        self.goals.append(goal)\n",
    "        self.states.append(state)\n",
    "        self.rewards.append(reward)\n",
    "        self.actions.append(action)\n",
    "\n",
    "        if prob is not None:\n",
    "            self.probs.append(prob)\n",
    "        if value is not None:\n",
    "            self.values.append(value)\n",
    "        if masks is not None:\n",
    "            self.masks.append(masks)\n",
    "\n",
    "    def calc_advantage(self, gamma: float, gae_lambda: float) -> np.ndarray:\n",
    "        n = len(self.rewards)\n",
    "        advantages = np.zeros(n)\n",
    "        for t in range(n - 1):\n",
    "            discount = 1\n",
    "            for k in range(t, n - 1):\n",
    "                advantages[t] += (\n",
    "                    discount\n",
    "                    * (\n",
    "                        self.rewards[k]\n",
    "                        + gamma * self.values[k + 1] * (1 - int(self.goals[k]))\n",
    "                    )\n",
    "                    - self.values[k]\n",
    "                )\n",
    "                discount *= gamma * gae_lambda\n",
    "        return list(advantages)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.goals)\n",
    "\n",
    "    def total_reward(self) -> float:\n",
    "        return sum(self.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferPPO(Buffer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_size: int,\n",
    "        batch_size: int,\n",
    "        gamma: float,\n",
    "        gae_lambda: float,\n",
    "        shuffle: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__(max_size, batch_size, shuffle)\n",
    "        self.gamma = gamma\n",
    "        self.gae_lambda = gae_lambda\n",
    "        self.episodes = deque(maxlen=max_size)\n",
    "        self.advantages = deque(maxlen=max_size)\n",
    "\n",
    "    def add(self, episode: Episode):\n",
    "        self.episodes.append(episode)\n",
    "        self.advantages.append(episode.calc_advantage(self.gamma, self.gae_lambda))\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.episodes.clear()\n",
    "        self.advantages.clear()\n",
    "\n",
    "    def get_len(self) -> int:\n",
    "        return len(self.episodes)\n",
    "\n",
    "    def sample(self):\n",
    "        probs = sum(map(lambda x: x.probs, self.episodes), [])\n",
    "        goals = sum(map(lambda x: x.goals, self.episodes), [])\n",
    "        masks = sum(map(lambda x: x.masks, self.episodes), [])\n",
    "        values = sum(map(lambda x: x.values, self.episodes), [])\n",
    "        states = sum(map(lambda x: x.states, self.episodes), [])\n",
    "        actions = sum(map(lambda x: x.actions, self.episodes), [])\n",
    "        rewards = sum(map(lambda x: x.rewards, self.episodes), [])\n",
    "        advantages = sum(self.advantages, [])\n",
    "\n",
    "        batches = make_batch_ids(\n",
    "            n=len(states), batch_size=self.batch_size, shuffle=self.shuffle\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            np.array(states),\n",
    "            np.array(actions),\n",
    "            np.array(rewards),\n",
    "            np.array(goals),\n",
    "            np.array(probs),\n",
    "            np.array(values),\n",
    "            np.array(masks),\n",
    "            np.array(advantages),\n",
    "            batches,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(\n",
    "        self, state_dim: int, action_dim: int, hidden_layers: tuple[int]\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.base_model = build_base_model(\n",
    "            state_dim, hidden_layers, action_dim, nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, states: T.Tensor, action_mask: T.Tensor):\n",
    "        x = self.base_model(states)\n",
    "        s = action_mask.sum(dim=1)\n",
    "        l = ((x * (1 - action_mask)).sum(dim=1) / s).unsqueeze(1)\n",
    "        x = (x + l) * action_mask\n",
    "        return Categorical(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim: int, hidden_layers: tuple[int]) -> None:\n",
    "        super().__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.model = build_base_model(state_dim, hidden_layers, 1)\n",
    "\n",
    "    def forward(self, state: T.Tensor):\n",
    "        return self.model(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(Learning):\n",
    "    def __init__(\n",
    "        self,\n",
    "        environment: gym.Env,\n",
    "        hidden_layers: tuple[int],\n",
    "        epochs: int,\n",
    "        buffer_size: int,\n",
    "        batch_size: int,\n",
    "        gamma: float = 0.99,\n",
    "        gae_lambda: float = 0.95,\n",
    "        policy_clip: float = 0.2,\n",
    "        learning_rate: float = 0.003,\n",
    "    ) -> None:\n",
    "        super().__init__(environment, epochs, gamma, learning_rate)\n",
    "\n",
    "        self.gae_lambda = gae_lambda\n",
    "        self.policy_clip = policy_clip\n",
    "        self.buffer = BufferPPO(\n",
    "            gamma=gamma,\n",
    "            max_size=buffer_size,\n",
    "            batch_size=batch_size,\n",
    "            gae_lambda=gae_lambda,\n",
    "        )\n",
    "\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.actor = Actor(self.state_dim, self.action_dim, hidden_layers)\n",
    "        self.critic = Critic(self.state_dim, hidden_layers)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=learning_rate)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=learning_rate)\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def take_action(self, state: np.ndarray, action_mask: np.ndarray):\n",
    "        state = T.Tensor(state).unsqueeze(0).to(self.device)\n",
    "        action_mask = T.Tensor(action_mask).unsqueeze(0).to(self.device)\n",
    "        dist = self.actor(state, action_mask)\n",
    "        action = dist.sample()\n",
    "        probs = T.squeeze(dist.log_prob(action)).item()\n",
    "        value = T.squeeze(self.critic(state)).item()\n",
    "        action = T.squeeze(action).item()\n",
    "        return action, probs, value\n",
    "\n",
    "    def epoch(self):\n",
    "        (\n",
    "            states_arr,\n",
    "            actions_arr,\n",
    "            rewards_arr,\n",
    "            goals_arr,\n",
    "            old_probs_arr,\n",
    "            values_arr,\n",
    "            masks_arr,\n",
    "            advantages_arr,\n",
    "            batches,\n",
    "        ) = self.buffer.sample()\n",
    "\n",
    "        for batch in batches:\n",
    "            masks = T.Tensor(masks_arr[batch]).to(self.device)\n",
    "            values = T.Tensor(values_arr[batch]).to(self.device)\n",
    "            states = T.Tensor(states_arr[batch]).to(self.device)\n",
    "            actions = T.Tensor(actions_arr[batch]).to(self.device)\n",
    "            old_probs = T.Tensor(old_probs_arr[batch]).to(self.device)\n",
    "            advantages = T.Tensor(advantages_arr[batch]).to(self.device)\n",
    "\n",
    "            dist = self.actor(states, masks)\n",
    "            critic_value = T.squeeze(self.critic(states))\n",
    "\n",
    "            new_probs = dist.log_prob(actions)\n",
    "            prob_ratio = (new_probs - old_probs).exp()\n",
    "\n",
    "            weighted_probs = advantages * prob_ratio\n",
    "            weighted_clipped_probs = (\n",
    "                T.clamp(prob_ratio, 1 - self.policy_clip, 1 + self.policy_clip)\n",
    "                * advantages\n",
    "            )\n",
    "\n",
    "            actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "            critic_loss = ((advantages + values - critic_value) ** 2).mean()\n",
    "            total_loss = actor_loss + 0.5 * critic_loss\n",
    "\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "            self.critic_optimizer.step()\n",
    "\n",
    "    def learn(self):\n",
    "        for epoch in tqdm(range(self.epochs), desc=\"PPO Learning...\", ncols=64, leave=False):\n",
    "            self.epoch()\n",
    "        self.buffer.clear()\n",
    "\n",
    "    def remember(self, episode: Episode):\n",
    "        self.buffer.add(episode)\n",
    "\n",
    "    def save(self, folder: str, name: str):\n",
    "        T.save(self, os.path.join(folder, f\"{name}.pt\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent(ABC):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: Chess,\n",
    "        learner: Learning,\n",
    "        episodes: int,\n",
    "        train_on: int,\n",
    "        result_folder: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.env = env\n",
    "        self.learner = learner\n",
    "        self.episodes = episodes\n",
    "        self.train_on = train_on\n",
    "        self.current_ep = 0\n",
    "        self.result_folder = result_folder\n",
    "\n",
    "        self.moves = np.zeros((2, episodes), dtype=np.uint32)\n",
    "        self.rewards = np.zeros((2, episodes))\n",
    "        self.mates_win = np.zeros((2, episodes), dtype=np.uint32)\n",
    "        self.checks_win = np.zeros((2, episodes), dtype=np.uint32)\n",
    "        self.mates_lose = np.zeros((2, episodes), dtype=np.uint32)\n",
    "        self.checks_lose = np.zeros((2, episodes), dtype=np.uint32)\n",
    "\n",
    "    def update_stats(self, infos: list[dict]):\n",
    "        for turn, info in enumerate(infos):\n",
    "            if CHECK_MATE_WIN in info:\n",
    "                self.mates_win[turn, self.current_ep] += 1\n",
    "\n",
    "            if CHECK_MATE_LOSE in info:\n",
    "                self.mates_lose[turn, self.current_ep] += 1\n",
    "\n",
    "            if CHECK_WIN in info:\n",
    "                self.checks_win[turn, self.current_ep] += 1\n",
    "\n",
    "            if CHECK_LOSE in info:\n",
    "                self.checks_lose[turn, self.current_ep] += 1\n",
    "\n",
    "    def take_action(self, turn: int, episode: Episode):\n",
    "        mask = self.env.get_all_actions(turn)[-1]\n",
    "        state = self.env.get_state(turn)\n",
    "\n",
    "        action, prob, value = self.learner.take_action(state, mask)\n",
    "        rewards, done, infos = self.env.step(action)\n",
    "        self.moves[turn, self.current_ep] += 1\n",
    "\n",
    "        self.update_stats(infos)\n",
    "        goal = CHECK_MATE_WIN in infos[turn]\n",
    "        episode.add(state, rewards[turn], action, goal, prob, value, mask)\n",
    "\n",
    "        return done, [state, rewards, action, goal, prob, value, mask]\n",
    "\n",
    "    def update_enemy(self, prev: list, episode: Episode, reward: int):\n",
    "        if prev is None:\n",
    "            return\n",
    "        prev[1] = reward\n",
    "        episode.add(*prev)\n",
    "\n",
    "    def train_episode(self, render: bool):\n",
    "        renders = []\n",
    "\n",
    "        def render_fn():\n",
    "            if self.env.render_mode != \"human\":\n",
    "                renders.append(self.env.render())\n",
    "\n",
    "        self.env.reset()\n",
    "        episode_white = Episode()\n",
    "        episode_black = Episode()\n",
    "        white_data: list = None\n",
    "        black_data: list = None\n",
    "        render_fn()\n",
    "\n",
    "        while True:\n",
    "            done, white_data = self.take_action(WHITE, episode_white)\n",
    "            self.update_enemy(black_data, episode_black, white_data[1][BLACK])\n",
    "            render_fn()\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            done, black_data = self.take_action(BLACK, episode_black)\n",
    "            self.update_enemy(white_data, episode_white, black_data[1][WHITE])\n",
    "            render_fn()\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        self.add_episodes(episode_white, episode_black)\n",
    "        self.rewards[BLACK, self.current_ep] = episode_black.total_reward()\n",
    "        self.rewards[WHITE, self.current_ep] = episode_white.total_reward()\n",
    "\n",
    "        if (render or self.env.done) and self.env.render_mode != \"human\":\n",
    "            path = os.path.join(self.result_folder, \"renders\", f\"episode_{self.current_ep}.mp4\")\n",
    "            save_to_video(path, np.array(renders))\n",
    "\n",
    "    def log(self, episode: int):\n",
    "        print(\n",
    "            f\"+ Episode {episode} Results [B | w]:\",\n",
    "            f\"\\t- Moves  = {self.moves[:, episode]}\",\n",
    "            f\"\\t- Reward = {self.rewards[:, episode]}\",\n",
    "            f\"\\t- Checks = {self.checks_win[:, episode]}\",\n",
    "            f\"\\t- Mates  = {self.mates_win[:, episode]}\",\n",
    "            \"-\" * 64,\n",
    "            sep=\"\\n\",\n",
    "        )\n",
    "\n",
    "    def tqdm_postfix(self, episode: int):\n",
    "        return {\n",
    "            \"episode\": episode,\n",
    "            \"moves\": self.moves[:, episode],\n",
    "            \"rewards\": self.rewards[:, episode],\n",
    "            \"checks\": self.checks_win[:, episode],\n",
    "            \"mates\": self.mates_win[:, episode]\n",
    "        }\n",
    "\n",
    "    def train(self, render_each: int, save_on_learn: bool = True):\n",
    "        for ep in (pbar := tqdm(range(self.episodes))):\n",
    "            self.train_episode(ep % render_each == 0 or ep == self.episodes - 1)\n",
    "            self.current_ep += 1\n",
    "            pbar.set_postfix(self.tqdm_postfix(ep))\n",
    "            if (ep + 1) % self.train_on == 0:\n",
    "                self.learn()\n",
    "                if save_on_learn:\n",
    "                    self.save()\n",
    "\n",
    "    def save(self):\n",
    "        folder = self.result_folder\n",
    "        np.save(os.path.join(folder, \"moves.npy\"), self.moves)\n",
    "        np.save(os.path.join(folder, \"rewards.npy\"), self.rewards)\n",
    "        np.save(os.path.join(folder, \"mates_win.npy\"), self.mates_win)\n",
    "        np.save(os.path.join(folder, \"mates_lose.npy\"), self.mates_lose)\n",
    "        np.save(os.path.join(folder, \"checks_win.npy\"), self.checks_win)\n",
    "        np.save(os.path.join(folder, \"checks_lose.npy\"), self.checks_lose)\n",
    "        self.save_learners()\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_learners(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def learn(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_episodes(self, white: Episode, black: Episode) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SingleAgentChess(BaseAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: Chess,\n",
    "        learner: Learning,\n",
    "        episodes: int,\n",
    "        train_on: int,\n",
    "        result_folder: str,\n",
    "    ) -> None:\n",
    "        super().__init__(env, learner, episodes, train_on, result_folder)\n",
    "\n",
    "    def add_episodes(self, white: Episode, black: Episode) -> None:\n",
    "        self.learner.remember(white)\n",
    "        self.learner.remember(black)\n",
    "\n",
    "    def learn(self):\n",
    "        self.learner.learn()\n",
    "\n",
    "    def save_learners(self):\n",
    "        self.learner.save(self.result_folder, \"single_agent_ppo.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess = Chess(window_size=512, max_steps=128, render_mode=\"rgb_array\")\n",
    "chess.reset()\n",
    "ppo = PPO(\n",
    "    chess,\n",
    "    hidden_layers=(2048,) * 4,\n",
    "    epochs=100,\n",
    "    buffer_size=buffer_size * 2,\n",
    "    batch_size=128,\n",
    ")\n",
    "\n",
    "print(ppo.device)\n",
    "print(ppo)\n",
    "print(\"-\" * 64)\n",
    "\n",
    "agent = SingleAgentChess(\n",
    "    env=chess,\n",
    "    learner=ppo,\n",
    "    episodes=2000,\n",
    "    train_on=buffer_size,\n",
    "    result_folder=\"./results/SingleAgent\",\n",
    ")\n",
    "agent.train(render_each=20, save_on_learn=True)\n",
    "agent.save()\n",
    "chess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QUEEN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m     board[:, \u001b[38;5;241m0\u001b[39m, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m)] \u001b[38;5;241m=\u001b[39m BISHOP\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m board\n\u001b[1;32m---> 37\u001b[0m board \u001b[38;5;241m=\u001b[39m \u001b[43minit_board\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_size\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m POSSIBLE_MOVES[name]\n",
      "Cell \u001b[1;32mIn[12], line 30\u001b[0m, in \u001b[0;36minit_board\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minit_board\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     29\u001b[0m     board \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m---> 30\u001b[0m     board[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mQUEEN\u001b[49m\n\u001b[0;32m     31\u001b[0m     board[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m=\u001b[39m KING\n\u001b[0;32m     32\u001b[0m     board[:, \u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m PAWN\n",
      "\u001b[1;31mNameError\u001b[0m: name 'QUEEN' is not defined"
     ]
    }
   ],
   "source": [
    "def init_pieces():\n",
    "        pieces = {\n",
    "            \"pawn_1\": (1, 0),\n",
    "            \"pawn_2\": (1, 1),\n",
    "            \"pawn_3\": (1, 2),\n",
    "            \"pawn_4\": (1, 3),\n",
    "            \"pawn_5\": (1, 4),\n",
    "            \"pawn_6\": (1, 5),\n",
    "            \"pawn_7\": (1, 6),\n",
    "            \"pawn_8\": (1, 7),\n",
    "            \"rook_1\": (0, 0),\n",
    "            \"rook_2\": (0, 7),\n",
    "            \"knight_1\": (0, 1),\n",
    "            \"knight_2\": (0, 6),\n",
    "            \"bishop_1\": (0, 2),\n",
    "            \"bishop_2\": (0, 5),\n",
    "            \"queen\": (0, 3),\n",
    "            \"king\": (0, 4),\n",
    "        }\n",
    "\n",
    "        return [pieces.copy(), pieces.copy()]\n",
    "pieces =init_pieces()\n",
    "\n",
    "def get_pieces_names() -> set:\n",
    "        return list(pieces[0].keys())\n",
    "pieces_names = get_pieces_names()\n",
    "\n",
    "def init_board() -> np.ndarray:\n",
    "    board = np.zeros((2, 8, 8), dtype=np.uint8)\n",
    "    board[:, 0, 3] = QUEEN\n",
    "    board[:, 0, 4] = KING\n",
    "    board[:, 1, :] = PAWN\n",
    "    board[:, 0, (0, 7)] = ROOK\n",
    "    board[:, 0, (1, 6)] = KNIGHT\n",
    "    board[:, 0, (2, 5)] = BISHOP\n",
    "    return board\n",
    "board = init_board()\n",
    "\n",
    "def get_size(name: str):\n",
    "        return POSSIBLE_MOVES[name]\n",
    "\n",
    "def get_source_pos(name: str, turn: int):\n",
    "        cat = name.split(\"_\")[0]\n",
    "        pos = pieces[turn][name]\n",
    "        if pos is None:\n",
    "            pos = (0, 0)\n",
    "        size = get_size(cat)\n",
    "        return np.array([pos] * size)\n",
    "\n",
    "\n",
    "def get_empty_actions(name: str):\n",
    "    size = get_size(name)\n",
    "    possibles = np.zeros((size, 2), dtype=np.int32)\n",
    "    actions_mask = np.zeros((size), dtype=np.int32)\n",
    "    return possibles, actions_mask\n",
    "\n",
    "def is_in_range( pos: Cell) -> bool:\n",
    "    row, col = pos\n",
    "    return row >= 0 and row <= 7 and col >= 0 and col <= 7\n",
    "\n",
    "def is_empty( pos: Cell, turn: int) -> bool:\n",
    "        return board[turn, pos[0], pos[1]] == EMPTY\n",
    "\n",
    "def is_enemy_king(pos: Cell, turn: int) -> bool:\n",
    "        r, c = pos\n",
    "        return board[1 - turn, 7 - r, c] == KING\n",
    "\n",
    "def piece_can_jump( pos: Cell, turn: int) -> bool:\n",
    "        jumps = {KNIGHT, KING}\n",
    "        piece = board[turn, pos[0], pos[1]]\n",
    "        return piece in jumps\n",
    "def both_side_empty(pos: Cell, turn: int) -> bool:\n",
    "    r, c = pos\n",
    "    return is_empty(pos, turn) and is_empty((7 - r, c), 1 - turn)\n",
    "\n",
    "def is_path_empty(current_pos: Cell, next_pos: Cell, turn: int) -> bool:\n",
    "        next_row, next_col = next_pos\n",
    "        current_row, current_col = current_pos\n",
    "\n",
    "        diff_row = next_row - current_row\n",
    "        diff_col = next_col - current_col\n",
    "        sign_row = np.sign(next_row - current_row)\n",
    "        sign_col = np.sign(next_col - current_col)\n",
    "\n",
    "        size = max(abs(diff_row), abs(diff_col)) - 1\n",
    "        rows = np.zeros(size, dtype=np.int32) + next_row\n",
    "        cols = np.zeros(size, dtype=np.int32) + next_col\n",
    "\n",
    "        if diff_row:\n",
    "            rows = np.arange(current_row + sign_row, next_row, sign_row, dtype=np.int32)\n",
    "\n",
    "        if diff_col:\n",
    "            cols = np.arange(current_col + sign_col, next_col, sign_col, dtype=np.int32)\n",
    "\n",
    "        for pos in zip(rows, cols):\n",
    "            if not both_side_empty(tuple(pos), turn):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "def general_validation(\n",
    "    current_pos: Cell,\n",
    "    next_pos: Cell,\n",
    "    turn: int,\n",
    "    deny_enemy_king: bool,\n",
    ") -> bool:\n",
    "    if not is_in_range(next_pos):\n",
    "        return False\n",
    "\n",
    "    if not is_empty(next_pos, turn):\n",
    "        return False\n",
    "\n",
    "    if is_enemy_king(next_pos, turn) and (not deny_enemy_king):\n",
    "        return False\n",
    "\n",
    "    if (not piece_can_jump(current_pos, turn)) and (\n",
    "        not is_path_empty(current_pos, next_pos, turn)\n",
    "    ):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def is_lead_to_check( current_pos: int, next_pos: int, turn: int) -> bool:\n",
    "    temp = Chess(render_mode=\"rgb_array\")\n",
    "    temp.board = np.copy(board)\n",
    "    temp.move_piece(current_pos, next_pos, turn)\n",
    "    return temp.is_check(temp.get_pos_king(turn), turn)\n",
    "\n",
    "def is_valid_move(\n",
    "    current_pos: Cell,\n",
    "    next_pos: Cell,\n",
    "    turn: int,\n",
    "    deny_enemy_king: bool,\n",
    ") -> bool:\n",
    "    if not general_validation(current_pos, next_pos, turn, deny_enemy_king):\n",
    "        return False\n",
    "    if is_lead_to_check(current_pos, next_pos, turn):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_for_enemy(pos: Cell, turn: int) -> bool:\n",
    "    r, c = pos\n",
    "    return not is_empty((7 - r, c), 1 - turn)\n",
    "\n",
    "def get_pos_king(turn: int) -> Cell:\n",
    "        row, col = np.where(board[turn] == KING)\n",
    "        return row[0], col[0]\n",
    "\n",
    "def is_neighbor_enemy_king(pos: Cell, turn: int) -> bool:\n",
    "    row, col = pos\n",
    "    row_enemy_king, col_enemy_king = get_pos_king(1 - turn)\n",
    "    row_enemy_king = 7 - row_enemy_king\n",
    "    diff_row = abs(row - row_enemy_king)\n",
    "    diff_col = abs(col - col_enemy_king)\n",
    "    return diff_row <= 1 and diff_col <= 1\n",
    "\n",
    "\n",
    "def get_actions_for_bishop(\n",
    "    pos: Cell, turn: int, deny_enemy_king: bool = False\n",
    "):\n",
    "    possibles, actions_mask = get_empty_actions(\"bishop\")\n",
    "    if pos is None:\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    row, col = pos\n",
    "    for i, (r, c) in enumerate(BISHOP_moves):\n",
    "        next_pos = (row + r, col + c)\n",
    "\n",
    "        if not is_valid_move(pos, next_pos, turn, deny_enemy_king):\n",
    "            continue\n",
    "\n",
    "        possibles[i] = next_pos\n",
    "        actions_mask[i] = 1\n",
    "\n",
    "    return possibles, actions_mask\n",
    "\n",
    "def get_actions_for_rook(pos: Cell, turn: int, deny_enemy_king: bool = False):\n",
    "    possibles, actions_mask = get_empty_actions(\"rook\")\n",
    "    if pos is None:\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    row, col = pos\n",
    "    for i, (r, c) in enumerate(ROOK_moves):\n",
    "        next_pos = (row + r, col + c)\n",
    "\n",
    "        if not is_valid_move(pos, next_pos, turn, deny_enemy_king):\n",
    "            continue\n",
    "\n",
    "        possibles[i] = next_pos\n",
    "        actions_mask[i] = 1\n",
    "\n",
    "    return possibles, actions_mask\n",
    "\n",
    "def get_action_for_queen(pos: Cell, turn: int, deny_enemy_king: bool = False):\n",
    "    possibles_rook, actions_mask_rook = get_actions_for_rook(\n",
    "        pos, turn, deny_enemy_king\n",
    "    )\n",
    "    possibles_bishop, actions_mask_bishop = get_actions_for_bishop(\n",
    "        pos, turn, deny_enemy_king\n",
    "    )\n",
    "    possibles = np.concatenate([possibles_bishop, possibles_rook])\n",
    "    actions_mask = np.concatenate([actions_mask_bishop, actions_mask_rook])\n",
    "\n",
    "    return possibles, actions_mask\n",
    "\n",
    "def get_actions_for_pawn(pos: Cell, turn: int, deny_enemy_king: bool = False):\n",
    "    possibles, actions_mask = get_empty_actions(\"pawn\")\n",
    "    if pos is None:\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    row, col = pos\n",
    "    if board[turn, row, col] == QUEEN:\n",
    "        return get_action_for_queen(pos, turn)\n",
    "\n",
    "    for i, (r, c) in enumerate(PAWN_moves[:4]):\n",
    "        next_pos = (row + r, col + c)\n",
    "\n",
    "        if not is_valid_move(pos, next_pos, turn, deny_enemy_king):\n",
    "            continue\n",
    "\n",
    "        can_moves = (\n",
    "            (r == 1 and c == 0 and both_side_empty(next_pos, turn)),\n",
    "            (r == 2 and row == 1 and both_side_empty(next_pos, turn)),\n",
    "            (r == 1 and abs(c) == 1 and check_for_enemy(next_pos, turn)),\n",
    "            # TODO: EN PASSANT\n",
    "        )\n",
    "\n",
    "        if True in can_moves:\n",
    "            possibles[i] = next_pos\n",
    "            actions_mask[i] = 1\n",
    "\n",
    "    return possibles, actions_mask\n",
    "\n",
    "def get_actions_for_knight(\n",
    "    pos: Cell, turn: int, deny_enemy_king: bool = False\n",
    "):\n",
    "    possibles, actions_mask = get_empty_actions(\"knight\")\n",
    "\n",
    "    if pos is None:\n",
    "        return possibles, actions_mask\n",
    "\n",
    "    row, col = pos\n",
    "    for i, (r, c) in enumerate(KNIGHT_moves):\n",
    "        next_pos = (row + r, col + c)\n",
    "        if not is_valid_move(pos, next_pos, turn, deny_enemy_king):\n",
    "            continue\n",
    "\n",
    "        possibles[i] = next_pos\n",
    "        actions_mask[i] = 1\n",
    "\n",
    "    return possibles, actions_mask\n",
    "\n",
    "def get_actions_for_king(pos: Cell, turn: int):\n",
    "    pos\n",
    "    row, col = pos\n",
    "    possibles, actions_mask = get_empty_actions(\"king\")\n",
    "\n",
    "    for i, (r, c) in enumerate(KING_moves):\n",
    "        next_pos = (row + r, col + c)\n",
    "\n",
    "        if not is_valid_move(pos, next_pos, turn, False):\n",
    "            continue\n",
    "\n",
    "        if is_neighbor_enemy_king(next_pos, turn):\n",
    "            continue\n",
    "\n",
    "        possibles[i] = next_pos\n",
    "        actions_mask[i] = 1\n",
    "\n",
    "    return possibles, actions_mask\n",
    "def get_actions_for(name: str, turn: int, deny_enemy_king: bool = False):\n",
    "        assert name in pieces_names, f\"name not in {pieces_names}\"\n",
    "        piece_cat = name.split(\"_\")[0]\n",
    "        piece_pos = pieces[turn][name]\n",
    "        src_poses = get_source_pos(name, turn)\n",
    "\n",
    "        if piece_cat == \"pawn\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *get_actions_for_pawn(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"knight\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *get_actions_for_knight(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"rook\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *get_actions_for_rook(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"bishop\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *get_actions_for_bishop(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"queen\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *get_action_for_queen(piece_pos, turn, deny_enemy_king),\n",
    "            )\n",
    "\n",
    "        if piece_cat == \"king\":\n",
    "            return (\n",
    "                src_poses,\n",
    "                *get_actions_for_king(piece_pos, turn),\n",
    "            )\n",
    "def get_all_actions(turn: int, deny_enemy_king: bool = False):\n",
    "        all_possibles = []\n",
    "        all_source_pos = []\n",
    "        all_actions_mask = []\n",
    "        for name in pieces[turn].keys():\n",
    "            # DENY ENEMY KING == FOR CHECKMATE VALIDATION ONLY SO ....\n",
    "            if name == \"king\" and deny_enemy_king:\n",
    "                continue\n",
    "\n",
    "            source_pos, possibles, actions_mask = get_actions_for(\n",
    "                name, turn, deny_enemy_king\n",
    "            )\n",
    "            all_source_pos.append(source_pos)\n",
    "            all_possibles.append(possibles)\n",
    "            all_actions_mask.append(actions_mask)\n",
    "\n",
    "        return (\n",
    "            np.concatenate(all_source_pos),\n",
    "            np.concatenate(all_possibles),\n",
    "            np.concatenate(all_actions_mask),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "from Chessnut import Game\n",
    "import random\n",
    "\n",
    "def chess_bot(obs):\n",
    "    \"\"\"\n",
    "    Simple chess bot that prioritizes checkmates, then captures, queen promotions, then randomly moves.\n",
    "\n",
    "    Args:\n",
    "        obs: An object with a 'board' attribute representing the current board state as a FEN string.\n",
    "\n",
    "    Returns:\n",
    "        A string representing the chosen move in UCI notation (e.g., \"e2e4\")\n",
    "    \"\"\"\n",
    "    # 0. Parse the current board state and generate legal moves using Chessnut library\n",
    "    game = Game(obs.board)\n",
    "    moves = list(game.get_moves())\n",
    "    print(game.get_fen().split(' ')[1])\n",
    "    game.get_fen()\n",
    "    \n",
    "    # 1. convert chessnut observation to local \n",
    "\n",
    "    for move in moves[:10]:\n",
    "        g = Game(obs.board)\n",
    "        g.apply_move(move)\n",
    "        if g.status == Game.CHECKMATE:\n",
    "            return move\n",
    "\n",
    "    # 2. Check for captures\n",
    "    for move in moves:\n",
    "        if game.board.get_piece(Game.xy2i(move[2:4])) != ' ':\n",
    "            return move\n",
    "\n",
    "    # 3. Check for queen promotions\n",
    "    for move in moves:\n",
    "        if \"q\" in move.lower():\n",
    "            return move\n",
    "\n",
    "    # 4. Random move if no checkmates or captures\n",
    "    return random.choice(moves)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "A = 0.25\n",
    "B = \"tab:blue\"\n",
    "W = \"tab:orange\"\n",
    "\n",
    "\n",
    "def ma(arr, count):\n",
    "    l = len(arr)\n",
    "    m = []\n",
    "    for i in range(count, l):\n",
    "        j = i - count\n",
    "        m.append(np.mean(arr[j:i]))\n",
    "    return np.array(m)\n",
    "\n",
    "\n",
    "def plot(ax, arr, title, episodes=-1, alpha=A, legend=True):\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim([0, episodes])\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    for i in range(2):\n",
    "        l = \"White\" if i else \"Black\"\n",
    "        c = W if i else B\n",
    "        ax.plot(arr[i, :episodes], label=l, alpha=alpha, c=c)\n",
    "    if legend:\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_ma(ax, arr, episodes=-1, count: int = 50):\n",
    "    for i in range(2):\n",
    "        c = W if i else B\n",
    "        ax.plot(range(count, episodes), ma(arr[i, :episodes], count), c=c, alpha=1)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def bar(ax, arr, title, episodes, alpha=A):\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.set_xlim([0, lst])\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "    for i in range(2):\n",
    "        l = \"White\" if i else \"Black\"\n",
    "        h = arr[i, :episodes]\n",
    "        x = range(lst)\n",
    "        ax.bar(x, h, label=l, alpha=alpha)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_moves(ax, moves, episodes, count: int = 50):\n",
    "    arr = moves.sum(axis=0)[:episodes]\n",
    "    ax.plot(arr, alpha=A, c=B)\n",
    "    ax.plot(range(count, episodes), ma(arr, count), alpha=1, c=B)\n",
    "    ax.set_title(\"Total Moves\")\n",
    "    ax.set_xlim([0, episodes])\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.grid()\n",
    "\n",
    "\n",
    "def density(arr, count, episode):\n",
    "    a = arr.max(axis=0)\n",
    "    return [np.sum(a[max(0, i - count) : i]) / count for i in range(episode)]\n",
    "\n",
    "\n",
    "def plot_check_mates(\n",
    "    ax, check_mates_arr: np.ndarray, episodes: int, count_density: int\n",
    "):\n",
    "    #     ax.plot(check_mates_arr.max(axis=0)[:episodes], alpha=0.25)\n",
    "    density_ax = ax.twinx()\n",
    "    density_arr = density(check_mates_arr, count_density, episodes)\n",
    "    density_ax.plot(\n",
    "        range(episodes),\n",
    "        density_arr,\n",
    "        color=\"tab:green\",\n",
    "        alpha=1,\n",
    "        label=f\"total check mates rate for {count_density} episodes\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    density_ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    density_ax.legend()\n",
    "    density_ax.grid()\n",
    "    plot(ax, check_mates_arr, \"Check Mates\", episodes, alpha=0.25, legend=False)\n",
    "\n",
    "\n",
    "ALPHA = 0.25\n",
    "COUNT = 512  # 512\n",
    "for name in [\"Double Agents\", \"Single Agent\"]:\n",
    "    print(name, \"...\")\n",
    "    folder = \"\".join(name.split(\" \"))\n",
    "    folder = f\"results/{folder}\"\n",
    "    moves = np.load(f\"{folder}/moves.npy\")\n",
    "    mates = np.load(f\"{folder}/mates_win.npy\")\n",
    "    checks = np.load(f\"{folder}/checks_win.npy\")\n",
    "    rewards = np.load(f\"{folder}/rewards.npy\")\n",
    "    episodes = np.max(np.where(moves[0] != 0)) + 1\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 12), dpi=200)\n",
    "    fig.suptitle(f\"{name} | {episodes} Episodes\")\n",
    "\n",
    "    plot(axs[0, 0], rewards, \"Rewards\", episodes, alpha=ALPHA)\n",
    "    plot_ma(axs[0, 0], rewards, episodes, count=32)\n",
    "\n",
    "    plot_moves(axs[0, 1], moves, episodes, count=32)\n",
    "\n",
    "    plot(axs[1, 0], checks, \"Checks\", episodes, alpha=ALPHA)\n",
    "    plot_ma(axs[1, 0], checks, episodes, count=32)\n",
    "\n",
    "    plot_check_mates(axs[1, 1], mates, episodes, COUNT)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{folder}/plots.jpeg\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "device = \"cuda\"\n",
    "#sys.setrecursionlimit(100)\n",
    "env = Chess(window_size=600)\n",
    "env.render()\n",
    "ppo = PPO(\n",
    "    env,\n",
    "    hidden_layers=(2048,) * 4,\n",
    "    epochs=100,\n",
    "    buffer_size=32 * 2,\n",
    "    batch_size=128,\n",
    ")\n",
    "ppo=T.load(\"results/SingleAgent/single_agent_ppo.pt.pt\")\n",
    "actor = Actor(env.observation_space.shape[0],env.action_space.n,hidden_layers=(2048,) * 4)\n",
    "#actor.load_state_dict(T.load(\"results/SingleAgent/single_agent_ppo.pt.pt\"))\n",
    "actor = ppo.actor\n",
    "\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        # if event.type == pygame.KEYDOWN:\n",
    "        #     if event.key != pygame.K_SPACE:\n",
    "        #         continue\n",
    "        #     else:\n",
    "    turn = env.turn\n",
    "    print(\"White\" if turn else \"Black\")\n",
    "    src, dst, mask = env.get_all_actions(turn)\n",
    "\n",
    "    #action = random.sample(list(np.where(mask == 1)[0]), 1)[0]\n",
    "    state = T.Tensor(env.get_state(turn)).unsqueeze(0).to(device)\n",
    "    action_mask = T.Tensor(env.get_all_actions(turn)[-1]).unsqueeze(0).to(device)\n",
    "    print(action_mask.shape)\n",
    "    dist = actor(state,action_mask)\n",
    "    action = dist.sample()\n",
    "    action = T.squeeze(action).item()\n",
    "    #print(action)\n",
    "    #print(f\"Action = {action}\", src[action], dst[action])\n",
    "    rewards, done, infos = env.step(action)\n",
    "    #print(f\"Rewards = {rewards}\")\n",
    "    #print(f\"Infos = {infos}\")\n",
    "    #print(\"-\" * 64)\n",
    "    env.render()\n",
    "    if done:\n",
    "        break\n",
    "        env.reset()\n",
    "\n",
    "        print(\"RESET\")\n",
    "\n",
    "\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing your agent\n",
    "\n",
    "Now let's see how your agent does againt the random agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = env.run([\"main.py\", \"random\"])\n",
    "print(\"Agent exit status/reward/time left: \")\n",
    "# look at the generated replay.json and print out the agent info\n",
    "for agent in result[-1]:\n",
    "    print(\"\\t\", agent.status, \"/\", agent.reward, \"/\", agent.observation.remainingOverageTime)\n",
    "print(\"\\n\")\n",
    "# render the game\n",
    "env.render(mode=\"ipython\", width=1000, height=1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Submit:\n",
    "1. Download (or save) main.py\n",
    "2. Go to the [submissions page](https://www.kaggle.com/competitions/fide-google-efficiency-chess-ai-challenge/submissions) and click \"Submit Agent\"\n",
    "3. Upload main.py\n",
    "4. Press Submit!\n",
    "\n",
    "Now doubt you are already thinking of ways this bot could be improved! Go ahead and fork this notebook and get started! ♟️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting Multiple files \n",
    "### (or compressing your main.py)\n",
    "\n",
    "Set up your directory structure like this:\n",
    "```\n",
    "kaggle_submissions/\n",
    "  main.py\n",
    "  <other files as desired>\n",
    "```\n",
    "\n",
    "You can run `tar -czf submission.tar.gz -C kaggle_submissions .` and upload `submission.tar.gz`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
